{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of imdb_market_basket_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lGRAllgArUcg",
        "arabic-forwarding",
        "B2wchK4S6FSd",
        "I7dZSxBd1hWQ",
        "0KsAA5w_21g1",
        "z3NcLCryldUa"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "protecting-prague"
      },
      "source": [
        "# Project 2: Market-basket analysis - IMDB dataset"
      ],
      "id": "protecting-prague"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tough-romance"
      },
      "source": [
        "Project for the course of Algorithms for Massive Dataset <br> Nicolas Facchinetti 961648 <br> Antonio Belotti 960822"
      ],
      "id": "tough-romance"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGRAllgArUcg"
      },
      "source": [
        "# Set up the Spark enviorment"
      ],
      "id": "lGRAllgArUcg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1-A43y-raCw"
      },
      "source": [
        "We start by dowloading and installing all the needed tool to deal with Spark. In particular we are interested in obtainig a Java enviorment since Spark in written in Scala and so it need a JVM to run. Then we can download Apache Spark 3.1.2 with Hadoop 3.2 by the Apache CDN and uncompress it. Finally we can get and install PySpark, an interface for Apache Spark in Python"
      ],
      "id": "G1-A43y-raCw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylCDuP_tsDRB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "473dc4ff-ed4c-4184-f4aa-4862dda26de9"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget https://dlcdn.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!rm spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ],
      "id": "ylCDuP_tsDRB",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-03 14:04:37--  https://dlcdn.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
            "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
            "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228834641 (218M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.1.2-bin-hadoop3.2.tgz’\n",
            "\n",
            "spark-3.1.2-bin-had 100%[===================>] 218.23M   195MB/s    in 1.1s    \n",
            "\n",
            "2022-02-03 14:04:38 (195 MB/s) - ‘spark-3.1.2-bin-hadoop3.2.tgz’ saved [228834641/228834641]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3amH6p0nwb7I"
      },
      "source": [
        "The next step is to correctly set the path in our remote enviorment to use the obtained tools."
      ],
      "id": "3amH6p0nwb7I"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXdPB9pQvM6Y"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\""
      ],
      "id": "EXdPB9pQvM6Y",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMGP-hYawvcv"
      },
      "source": [
        "Finally we can import PySpark in the project"
      ],
      "id": "IMGP-hYawvcv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Imf5XE-w84G"
      },
      "source": [
        "import findspark\n",
        "findspark.init(\"spark-3.1.2-bin-hadoop3.2\")# SPARK_HOME\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "id": "2Imf5XE-w84G",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJMEDFZ34-i3"
      },
      "source": [
        "# Load preprocessed dataset from file data.zip"
      ],
      "id": "nJMEDFZ34-i3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdFAFOdx5Q6n"
      },
      "source": [
        "Use the code below do load the dataset from a preprocessed file data.zip"
      ],
      "id": "LdFAFOdx5Q6n"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ0o6v56gAGE",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "279da5c7-63b2-4dde-e6ec-8df5ee92c766"
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "if os.path.isfile(\"data.zip\"):\n",
        "  !unzip -q data.zip && rm data.zip\n",
        "  basket_data = spark.read.format(\"json\").option(\"header\", \"true\").load(\"data\").select('tconst', 'nconsts').rdd\n",
        "  basket_data.take(5)\n",
        "else:\n",
        "  print(\"Error in loading the file.\")"
      ],
      "id": "kQ0o6v56gAGE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-eedf6e6c-133c-4e17-b67d-64f546ce8682\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-eedf6e6c-133c-4e17-b67d-64f546ce8682\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data.zip to data.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arabic-forwarding"
      },
      "source": [
        "# Download the dataset from Kaggle"
      ],
      "id": "arabic-forwarding"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cardiac-significance"
      },
      "source": [
        "First install the Python module of Kaggle to download the dataset from its datacenter"
      ],
      "id": "cardiac-significance"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "third-confidence",
        "outputId": "ac2d112b-1032-4d27-e570-5b2576118b40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install kaggle"
      ],
      "id": "third-confidence",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "attractive-recall"
      },
      "source": [
        "Then load kaggle.json, a file containing your API credentials to be able to use the services offered by Kaggle"
      ],
      "id": "attractive-recall"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "narrow-future",
        "outputId": "556fe1fb-10ae-4ee0-e3f1-e67bb90ca65b",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "  \n",
        "# Move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "id": "narrow-future",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-557b7734-98fe-467c-ab22-d2d385fea768\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-557b7734-98fe-467c-ab22-d2d385fea768\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "entitled-stanley"
      },
      "source": [
        "Now we can download the dataset"
      ],
      "id": "entitled-stanley"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "built-indianapolis",
        "outputId": "239bb126-dcd6-4e06-ec82-7ec383767d0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!kaggle datasets download 'ashirwadsangwan/imdb-dataset'"
      ],
      "id": "built-indianapolis",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading imdb-dataset.zip to /content\n",
            " 99% 1.42G/1.44G [00:17<00:00, 89.4MB/s]\n",
            "100% 1.44G/1.44G [00:17<00:00, 88.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naked-dinner"
      },
      "source": [
        "We now must unzip the compressed archive to use it. Once done we can also remove it."
      ],
      "id": "naked-dinner"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "every-homework",
        "outputId": "27df198c-e486-4ce7-8d91-7bcedad81085",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!unzip imdb-dataset.zip && rm imdb-dataset.zip"
      ],
      "id": "every-homework",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  imdb-dataset.zip\n",
            "  inflating: name.basics.tsv.gz      \n",
            "  inflating: name.basics.tsv/name.basics.tsv  \n",
            "  inflating: title.akas.tsv.gz       \n",
            "  inflating: title.akas.tsv/title.akas.tsv  \n",
            "  inflating: title.basics.tsv.gz     \n",
            "  inflating: title.basics.tsv/title.basics.tsv  \n",
            "  inflating: title.principals.tsv.gz  \n",
            "  inflating: title.principals.tsv/title.principals.tsv  \n",
            "  inflating: title.ratings.tsv.gz    \n",
            "  inflating: title.ratings.tsv/title.ratings.tsv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2wchK4S6FSd"
      },
      "source": [
        "# Preapare the data for Spark"
      ],
      "id": "B2wchK4S6FSd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkCLCyVf6P81"
      },
      "source": [
        "We can directly load the downloaded and extracted .tsv file in a Spark DataFrame by using the command read.csv(). We directly pass to the method the columns in which we are interested."
      ],
      "id": "vkCLCyVf6P81"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9yN4DYO5rA9",
        "outputId": "a308d09e-2a0f-4918-e324-60c8e613216a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_principals = spark.read.csv(\"/content/title.principals.tsv/title.principals.tsv\", sep=r'\\t', header=True).select('tconst','nconst','category')\n",
        "df_principals.show(10)"
      ],
      "id": "o9yN4DYO5rA9",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+---------------+\n",
            "|   tconst|   nconst|       category|\n",
            "+---------+---------+---------------+\n",
            "|tt0000001|nm1588970|           self|\n",
            "|tt0000001|nm0005690|       director|\n",
            "|tt0000001|nm0374658|cinematographer|\n",
            "|tt0000002|nm0721526|       director|\n",
            "|tt0000002|nm1335271|       composer|\n",
            "|tt0000003|nm0721526|       director|\n",
            "|tt0000003|nm5442194|       producer|\n",
            "|tt0000003|nm1335271|       composer|\n",
            "|tt0000003|nm5442200|         editor|\n",
            "|tt0000004|nm0721526|       director|\n",
            "+---------+---------+---------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biVqVaIO6rm1",
        "outputId": "fea620e0-e679-46c0-e416-eee1ab572d40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_basics = spark.read.csv(\"/content/title.basics.tsv/title.basics.tsv\", sep=r'\\t', header=True).select('tconst','titleType')\n",
        "df_basics.show(10)"
      ],
      "id": "biVqVaIO6rm1",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+\n",
            "|   tconst|titleType|\n",
            "+---------+---------+\n",
            "|tt0000001|    short|\n",
            "|tt0000002|    short|\n",
            "|tt0000003|    short|\n",
            "|tt0000004|    short|\n",
            "|tt0000005|    short|\n",
            "|tt0000006|    short|\n",
            "|tt0000007|    short|\n",
            "|tt0000008|    short|\n",
            "|tt0000009|    movie|\n",
            "|tt0000010|    short|\n",
            "+---------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYEMZq6g8V8r"
      },
      "source": [
        "By inspecting the content of the column 'category' of df_principlas we can see that there are many jobs other than actors and actress (which are the two we are interested in)"
      ],
      "id": "jYEMZq6g8V8r"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ANddVhG7dOM",
        "outputId": "e45a321d-f678-4db2-b1f2-730fd451ca26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_principals.select(\"category\").distinct().show()"
      ],
      "id": "_ANddVhG7dOM",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+\n",
            "|           category|\n",
            "+-------------------+\n",
            "|            actress|\n",
            "|           producer|\n",
            "|             writer|\n",
            "|           composer|\n",
            "|           director|\n",
            "|               self|\n",
            "|              actor|\n",
            "|             editor|\n",
            "|    cinematographer|\n",
            "|      archive_sound|\n",
            "|production_designer|\n",
            "|    archive_footage|\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chgrEDU181jc"
      },
      "source": [
        "Similarly we can do the same thing with df_basics and the column 'titleType' to see how many categories a title can have."
      ],
      "id": "chgrEDU181jc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0k9A__I8uop",
        "outputId": "5526de9c-2d90-41ae-d77c-5a48cca57cd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_basics.select(\"titleType\").distinct().show()"
      ],
      "id": "H0k9A__I8uop",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+\n",
            "|   titleType|\n",
            "+------------+\n",
            "|    tvSeries|\n",
            "|tvMiniSeries|\n",
            "|     tvMovie|\n",
            "|   tvEpisode|\n",
            "|       movie|\n",
            "|   tvSpecial|\n",
            "|       video|\n",
            "|   videoGame|\n",
            "|     tvShort|\n",
            "|       short|\n",
            "+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRGTAAFK7QJ0"
      },
      "source": [
        "Once the data is loaded in a Spark DataFrame we can use the PySpark SQL module for processing the data. We start by exctracting only actors and actress from df_principals"
      ],
      "id": "WRGTAAFK7QJ0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wrOWYKr8UC3",
        "outputId": "08dbb947-0273-4962-e78b-1985aa226155",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pre = df_principals.count()\n",
        "df_principals.createOrReplaceTempView(\"PRINCIPALS\") # create a temporary table on DataFrame\n",
        "df_principals = spark.sql(\"SELECT * from PRINCIPALS WHERE category ='actor' OR category='actress'\")\n",
        "print(\"We reduced the number of row from {} to {}\".format(pre, df_principals.count()))"
      ],
      "id": "0wrOWYKr8UC3",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We reduced the number of row from 36468817 to 14818798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFE8PdWZ9UAa"
      },
      "source": [
        " And then we do the same thing with movies in df_basics"
      ],
      "id": "QFE8PdWZ9UAa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7idYi-s9ZlZ",
        "outputId": "4ad152a5-34a8-41dc-dc40-f7876718d23e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pre = df_basics.count()\n",
        "df_basics.createOrReplaceTempView(\"BASICS\") # create a temporary table on DataFrame\n",
        "df_basics = spark.sql(\"SELECT * from BASICS WHERE titleType ='movie'\")\n",
        "print(\"We reduced the number of row from {} to {}\".format(pre, df_basics.count()))"
      ],
      "id": "_7idYi-s9ZlZ",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We reduced the number of row from 6321302 to 536034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhZYta_8TBU1"
      },
      "source": [
        "We can now see that we have two DataFrame, one containing only the movies and the other only the people which play as actor/actress in a title. To do the desired maket-basket analysis we have to pivot our tconst as rows, so each row stands for one titleId, and then including a list of nconst identifiers of the actors that played in it."
      ],
      "id": "AhZYta_8TBU1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg5cCJD1Swlg",
        "outputId": "44ca51cc-58f2-4767-c11d-6b3e8e2f4b73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_basics.show(10)"
      ],
      "id": "Gg5cCJD1Swlg",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+\n",
            "|   tconst|titleType|\n",
            "+---------+---------+\n",
            "|tt0000009|    movie|\n",
            "|tt0000147|    movie|\n",
            "|tt0000335|    movie|\n",
            "|tt0000502|    movie|\n",
            "|tt0000574|    movie|\n",
            "|tt0000615|    movie|\n",
            "|tt0000630|    movie|\n",
            "|tt0000675|    movie|\n",
            "|tt0000676|    movie|\n",
            "|tt0000679|    movie|\n",
            "+---------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BnEuTc0S9Xm",
        "outputId": "51d52bcd-a51b-4978-a5b8-0626bd037a53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_principals.show(10)"
      ],
      "id": "7BnEuTc0S9Xm",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+--------+\n",
            "|   tconst|   nconst|category|\n",
            "+---------+---------+--------+\n",
            "|tt0000005|nm0443482|   actor|\n",
            "|tt0000005|nm0653042|   actor|\n",
            "|tt0000007|nm0179163|   actor|\n",
            "|tt0000007|nm0183947|   actor|\n",
            "|tt0000008|nm0653028|   actor|\n",
            "|tt0000009|nm0063086| actress|\n",
            "|tt0000009|nm0183823|   actor|\n",
            "|tt0000009|nm1309758|   actor|\n",
            "|tt0000011|nm3692297|   actor|\n",
            "|tt0000014|nm0166380|   actor|\n",
            "+---------+---------+--------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuwFSQN1VyCV"
      },
      "source": [
        "So we start by joining the two dataframe to extract from df_principals only the records with tconst related to a movie. We can also discard the category column since is no longer useful."
      ],
      "id": "QuwFSQN1VyCV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81uUuBOVVj3a",
        "outputId": "bfe2e8cb-74b9-4bd3-87b5-34c8d8ce57f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "basket_data = df_principals.join(df_basics, \"tconst\").select(df_principals.tconst, df_principals.nconst).sort(\"tconst\")\n",
        "basket_data.show(10)"
      ],
      "id": "81uUuBOVVj3a",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+\n",
            "|   tconst|   nconst|\n",
            "+---------+---------+\n",
            "|tt0000009|nm0183823|\n",
            "|tt0000009|nm1309758|\n",
            "|tt0000009|nm0063086|\n",
            "|tt0000335|nm0675239|\n",
            "|tt0000335|nm1010955|\n",
            "|tt0000335|nm0675260|\n",
            "|tt0000335|nm1012612|\n",
            "|tt0000335|nm1012621|\n",
            "|tt0000335|nm1011210|\n",
            "|tt0000502|nm0215752|\n",
            "+---------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHywTOMEZbgu"
      },
      "source": [
        "Then we can remove hypothetical duplicated row and then aggregate the data using tconst identifier."
      ],
      "id": "xHywTOMEZbgu"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYN6WQg5Vj4x"
      },
      "source": [
        "from pyspark.sql import functions as F\n",
        "basket_data = basket_data.dropDuplicates()\n",
        "basket_data = basket_data.groupBy(\"tconst\").agg(F.collect_list(\"nconst\").alias(\"nconsts\")).sort('tconst')"
      ],
      "id": "IYN6WQg5Vj4x",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZzSHEsFaa0G",
        "outputId": "7e951bb2-dc29-4500-c064-e0a8c53edcf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"There are {} titleId buckets\".format(basket_data.count()))\n",
        "basket_data.show(10, False)"
      ],
      "id": "IZzSHEsFaa0G",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 393656 titleId buckets\n",
            "+---------+------------------------------------------------------------------+\n",
            "|tconst   |nconsts                                                           |\n",
            "+---------+------------------------------------------------------------------+\n",
            "|tt0000009|[nm0063086, nm0183823, nm1309758]                                 |\n",
            "|tt0000335|[nm1010955, nm1012612, nm1011210, nm1012621, nm0675239, nm0675260]|\n",
            "|tt0000502|[nm0215752, nm0252720]                                            |\n",
            "|tt0000574|[nm0846887, nm0846894, nm3002376, nm0170118]                      |\n",
            "|tt0000615|[nm3071427, nm0581353, nm0888988, nm0240418, nm0346387, nm0218953]|\n",
            "|tt0000630|[nm0624446]                                                       |\n",
            "|tt0000676|[nm0097421, nm0140054]                                            |\n",
            "|tt0000679|[nm0000875, nm0122665, nm0933446, nm2924919]                      |\n",
            "|tt0000793|[nm0691995]                                                       |\n",
            "|tt0000862|[nm5289318, nm5289829, nm0264569, nm0386036, nm0511080, nm5188470]|\n",
            "+---------+------------------------------------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOFUnUEZclPs"
      },
      "source": [
        "As we can see above we now have the data in the correct format to do our analysis: in each row we have the identifier of a movie and in the second column the list of the idenfiers of the actors that played in it.\n",
        "Since we have done all the needed pre-processing computation on the data we can transform our DataFrame in a RDD to apply map-reduce functions."
      ],
      "id": "JOFUnUEZclPs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PXtfoBH41dy"
      },
      "source": [
        "Serialize to file the RDD and download to skip the processing all the time.\n",
        "\n"
      ],
      "id": "4PXtfoBH41dy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poNWxUnLm92f"
      },
      "source": [
        "basket_data.write.format('json').save(\"data\")"
      ],
      "id": "poNWxUnLm92f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_0NCykYVZeB"
      },
      "source": [
        "!zip -r data.zip data"
      ],
      "id": "c_0NCykYVZeB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXXeT6F0Vg5q"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('data.zip')"
      ],
      "id": "MXXeT6F0Vg5q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti7KSSed4h34"
      },
      "source": [
        "# Apriori classic"
      ],
      "id": "ti7KSSed4h34"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTGVInR_j-Fu"
      },
      "source": [
        "We start by implementing the classic Apriori algorithm. In particular we search until no more k-itemsets are found."
      ],
      "id": "UTGVInR_j-Fu"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_candidate_k_set(frequent_kmin1_set, k):\n",
        "  \"\"\"\n",
        "  frequent_kmin1_set: list\n",
        "  k: int\n",
        "\n",
        "  return: list\n",
        "\n",
        "  Take as input an integer k and a frequent k-1 itemset. Return as output the candidate k itemset obtained from frequent_kmin1_set\n",
        "  \"\"\"\n",
        "  if k < 2:\n",
        "      raise ValueError(\"k must be >= 2\")\n",
        "  candidates = []\n",
        "  if k == 2:\n",
        "      # generate pairs\n",
        "      for x in frequent_kmin1_set:\n",
        "          for y in frequent_kmin1_set:\n",
        "              # to prevent duplicates\n",
        "              if x < y:\n",
        "                  candidates.append((x, y))\n",
        "  else:\n",
        "    # generate itemsets k>2\n",
        "    for x in frequent_kmin1_set:\n",
        "      for y in frequent_kmin1_set:\n",
        "        \"\"\"\n",
        "        Items\tx and\ty in\tk-1 itemsets are\tjoined\tif\n",
        "        (x[1]=y[1]) ^ (x[2]=y[2]) ^ … ^ (x[k-2]=y[k-2])\n",
        "        (x[k-1]<y[k-1]) to prevent duplicates\n",
        "        \"\"\"\n",
        "        if x[:k - 2] == y[:k - 2] and x[k - 2] < y[k - 2]:\n",
        "          candidates.append((*x[:k - 2], x[k - 2], y[k - 2]))\n",
        "  return candidates"
      ],
      "metadata": {
        "id": "zUn2HchZukHA"
      },
      "id": "zUn2HchZukHA",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "                    \n",
        "def apriori_unlimited_k(transactions, support_threshold):\n",
        "  \"\"\"\n",
        "  transactions: list [(key, [elements]), ...]\n",
        "  support_threshold: int\n",
        "\n",
        "  return: list [(itemset, support), ...]\n",
        "  \"\"\"\n",
        "  frequent_elements = {}\n",
        "\n",
        "  # count singletons\n",
        "  counter = {}\n",
        "  for _, transaction in transactions:\n",
        "    for x in transaction:\n",
        "      # if is not present in counter set return 0 and add 1, otherwise add 1 to entry x\n",
        "      counter[x] = counter.get(x,0) + 1\n",
        "\n",
        "  # filter out imtesets with count >= the threshold\n",
        "  frequent_elements[1] = [(k, v) for k, v in counter.items() if v >= support_threshold]\n",
        "  \n",
        "  k = 2\n",
        "  while True:\n",
        "    all_candidate_sets = generate_candidate_k_set([e[0] for e in frequent_elements[k - 1]], k)\n",
        "    if len(all_candidate_sets) == 0:\n",
        "      # no more candidate set\n",
        "      break\n",
        "\n",
        "    counter = {}\n",
        "    for _, transaction in transactions:\n",
        "      for candidate_set in all_candidate_sets:\n",
        "        # check that all the element in the candidate set are in transaction\n",
        "        if all([candidate_element in transaction for candidate_element in candidate_set]):\n",
        "          counter[candidate_set] = counter.get(candidate_set, 0) + 1\n",
        "    # keep only the itemsets with counter >= the threshold\n",
        "    frequent_elements[k] = [(itemset, occ) for itemset, occ in counter.items() if occ >= support_threshold]\n",
        "    k += 1\n",
        "  return functools.reduce(lambda a, b: a + b, frequent_elements.values())"
      ],
      "metadata": {
        "id": "F7SMmiPiiQrQ"
      },
      "id": "F7SMmiPiiQrQ",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = [\n",
        "        (\"t1\", [\"I1\", \"I3\", \"I4\"]),\n",
        "        (\"t2\", [\"I2\", \"I3\", \"I5\"]),\n",
        "        (\"t3\", [\"I1\", \"I2\", \"I3\", \"I5\"]),\n",
        "        (\"t4\", [\"I2\", \"I5\"]),\n",
        "  ]\n",
        "\n",
        "apriori_unlimited_k(test, 2)"
      ],
      "metadata": {
        "id": "1rQVnV3xoz7p",
        "outputId": "a97a3d4c-3f55-4541-fd05-b4827edf240a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1rQVnV3xoz7p",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I1', 2),\n",
              " ('I3', 3),\n",
              " ('I2', 3),\n",
              " ('I5', 3),\n",
              " (('I1', 'I3'), 2),\n",
              " (('I3', 'I5'), 2),\n",
              " (('I2', 'I3'), 2),\n",
              " (('I2', 'I5'), 3),\n",
              " (('I2', 'I3', 'I5'), 2)]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7dZSxBd1hWQ"
      },
      "source": [
        "# Apriori with MAP-REDUCE"
      ],
      "id": "I7dZSxBd1hWQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYDq3kNh5aql"
      },
      "source": [
        "Follow an implementatio of the Apriori algorithm using a map-reduce approach."
      ],
      "id": "YYDq3kNh5aql"
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_candidate(transaction, all_candidate_sets):\n",
        "  \"\"\"\n",
        "  transaction: list\n",
        "  all_candidate_set: list\n",
        "\n",
        "  return: list\n",
        "  return only the candidate set which are in the transaction\n",
        "  \"\"\"\n",
        "  exist = []\n",
        "  for candidate_set in all_candidate_sets:\n",
        "    if all([candidate_element in transaction for candidate_element in candidate_set]):\n",
        "      exist.append(candidate_set)\n",
        "  return exist"
      ],
      "metadata": {
        "id": "2AlYVXPwD2yv"
      },
      "id": "2AlYVXPwD2yv",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apriorihmap_unlimited_k(data, support_threshold):\n",
        "  \"\"\" \n",
        "  data: Pyspark.rdd \n",
        "    [\n",
        "      [tconst, [nconst,]],\n",
        "    ]\n",
        "  support_threshold: int\n",
        "\n",
        "  return: Pyspark.rdd\n",
        "  \"\"\"\n",
        "  nconst_rdd = data.map(lambda x: x[1])\n",
        "\n",
        "  # find singletone\n",
        "  frequent_items_rdd = nconst_rdd.flatMap(lambda x: x) \\\n",
        "        .map(lambda elem: (elem,1)) \\\n",
        "        .reduceByKey(lambda a,b: a+b) \\\n",
        "        .filter(lambda x: x[1] >= support_threshold)\n",
        "\n",
        "  # to save frequent itemsets for each k iteration\n",
        "  frequent_elements = frequent_items_rdd.map(lambda x: x[0]).collect()\n",
        "  k = 2\n",
        "  # until there are no more frequent itemesets with support >= threshold\n",
        "  while frequent_elements:\n",
        "    # generate all the candidate k itemset from frequent_elements (k - 1)\n",
        "    all_candidate_sets = generate_candidate_k_set(frequent_elements, k) \n",
        "    \n",
        "    frequent_k_rdd = nconst_rdd.flatMap(lambda x: filter_candidate(x, all_candidate_sets)) \\\n",
        "              .map(lambda x: (x,1)) \\\n",
        "              .reduceByKey(lambda a,b: a+b) \\\n",
        "              .filter(lambda x: x[1] >= support_threshold)\n",
        "    frequent_items_rdd = frequent_items_rdd.union(frequent_k_rdd)\n",
        "\n",
        "    # add new frequent element\n",
        "    frequent_elements = frequent_k_rdd.map(lambda x: x[0]).collect()\n",
        "    k += 1\n",
        "  return frequent_items_rdd"
      ],
      "metadata": {
        "id": "qdt80B7guQcy"
      },
      "id": "qdt80B7guQcy",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KsAA5w_21g1"
      },
      "source": [
        "# SON"
      ],
      "id": "0KsAA5w_21g1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2Kk0QGUlr-X"
      },
      "source": [
        "We then decided to also implement SON to test out if there is an improvement in time complexity. We decided to partion the data in a number equal to the avaiable processors in the cluster for the sake of experimenta setup; in a real case scenario use the number of nodes in the cluster."
      ],
      "id": "P2Kk0QGUlr-X"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJgYWyXy28lB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c176fe12-056f-4358-a8dd-4891d6d8a3ef"
      },
      "source": [
        "# empirical sweet-spot for the number of partitions (assuming every executor has 4 cores ...)\n",
        "num_partitions = spark.sparkContext._jsc.sc().getExecutorMemoryStatus().size() * 4\n",
        "num_partitions"
      ],
      "id": "vJgYWyXy28lB",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJwtNWu9mNL3"
      },
      "source": [
        "We must define a function for the second step to properly count the number of occurrence of frequent itemsets in a partition."
      ],
      "id": "eJwtNWu9mNL3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGizCiVdI01u"
      },
      "source": [
        "def count_in_partition(data, frequent):\n",
        "  \"\"\"\n",
        "  data: iterable\n",
        "  frequent:  pyspark.Broadcast\n",
        "\n",
        "  return: list \n",
        "  \n",
        "  count the occurence of each itemeset in frequent in the partion data\n",
        "  \"\"\"\n",
        "  # prepare data for processing\n",
        "  frequent = frequent.value   # extract broadcasted values\n",
        "  data = list(data)           # cast to list to iterate more than one time\n",
        "\n",
        "  # check foreach frequent itemset\n",
        "  for frequent_item in frequent:\n",
        "    # trick to cast single element to list → not remove in the str duplicate char using set()\n",
        "    if type(frequent_item) is not tuple:\n",
        "      to_check = [frequent_item]\n",
        "    else:\n",
        "      to_check = frequent_item\n",
        "      \n",
        "    c = 0     # counter\n",
        "    # and foreach row of the dataset\n",
        "    for itemset in data:\n",
        "      # check if the frequent itemset is subset of the items of the row\n",
        "      if set(to_check).issubset(itemset[1]):\n",
        "        c += 1\n",
        "    yield (frequent_item, c)"
      ],
      "id": "eGizCiVdI01u",
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff6lKtG-gpYk"
      },
      "source": [
        "def count_in_partition_v2(data, candidate_frequent_itemsets_bv):\n",
        "  # extract broadcasted values\n",
        "  candidate_frequent_itemsets = candidate_frequent_itemsets_bv.value\n",
        "\n",
        "  # check foreach frequent itemset\n",
        "  for candidate_freq_item in candidate_frequent_itemsets.keys():\n",
        "    # need candidate_freq_item to be iterable even if it's only a single element\n",
        "    if type(candidate_freq_item) is not tuple:\n",
        "      candidate_freq_item = [candidate_freq_item]\n",
        "      \n",
        "    c = 0\n",
        "    for _, bucket in data:\n",
        "      if set(candidate_freq_item).issubset([x for x in bucket if candidate_frequent_itemsets.get(x,False)]):\n",
        "        c += 1\n",
        "    yield (tuple(candidate_freq_item), c)"
      ],
      "id": "ff6lKtG-gpYk",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "565n3mcLm4vX"
      },
      "source": [
        "Then the implementation of SON with a two step map-reduce. The first finds out the frequent itemsets in the partition and the latter go to count them in the dataset and filters out the ones with support greater than threshold."
      ],
      "id": "565n3mcLm4vX"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwaMIM_AI33k"
      },
      "source": [
        "def son_m_r(data, support):\n",
        "  \"\"\"\n",
        "  data: Pyspark.rdd \n",
        "    [\n",
        "      [tconst, [nconst,]],\n",
        "    ]\n",
        "  support: int\n",
        "\n",
        "  return: Pyspark.rdd\n",
        "  \"\"\"\n",
        "  reduced_support = support//data.getNumPartitions()\n",
        "  # use apriori on every partition\n",
        "  first_map = data.mapPartitions(lambda partition: apriori_unlimited_k(partition, reduced_support)).map(lambda x: (x[0], 1))\n",
        "  # TRYYYYYYYYYYY WITH DISTINCT ON TIME COMPLEXITY\n",
        "  first_reduce = first_map.reduceByKey(lambda a,b: a+b)       # possible to remove a+b ?????????????????\n",
        "\n",
        "  \n",
        "  # extract the frequent itemsets and broadcast them to worker nodes\n",
        "  frequent_items = [x[0] for x in first_reduce.collect()]\n",
        "  frequent_items = spark.sparkContext.broadcast(frequent_items)\n",
        "\n",
        "  second_map = data.mapPartitions(lambda partition: count_in_partition(partition, frequent_items))\n",
        "  second_reduce = second_map.reduceByKey(lambda a,b: a+b).filter(lambda x: x[1] >= support)\n",
        "  return second_reduce"
      ],
      "id": "BwaMIM_AI33k",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImC5plrpZ4wv"
      },
      "source": [
        "def son_m_r_v2(data, support):\n",
        "  reduced_support = support/data.getNumPartitions()  # mi sa che non si deve arrotondare. va bene se è un float altrimenti poterbbe uscire 0\n",
        "  candidate_frequent_itemsets_rdd = data.mapPartitions(lambda partition: apriori_unlimited_k(partition, reduced_support)).map(lambda x: x[0]).distinct()\n",
        "\n",
        "  # broadcast the frequent items to worker nodes\n",
        "  candidate_frequent_itemsets_bv = spark.sparkContext.broadcast(\n",
        "      {x:True for x in candidate_frequent_itemsets_rdd.collect()}\n",
        "  )\n",
        "\n",
        "  second_map = data.mapPartitions(lambda partition: count_in_partition_v2(partition, candidate_frequent_itemsets_bv))\n",
        "  frequent_itemsets = second_map.reduceByKey(lambda a,b: a+b).filter(lambda x: x[1] >= support)\n",
        "  return frequent_itemsets"
      ],
      "id": "ImC5plrpZ4wv",
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3NcLCryldUa"
      },
      "source": [
        "# Demo FP Growth"
      ],
      "id": "z3NcLCryldUa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nE0iULGnbS1"
      },
      "source": [
        "To carry our experiment we decided to also use the in library implementation of FP-growth as comparison benchmark."
      ],
      "id": "1nE0iULGnbS1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz6FTwiSlgtB"
      },
      "source": [
        "from pyspark.ml.fpm import FPGrowth\n",
        "fpGrowth = FPGrowth(itemsCol=\"nconsts\")"
      ],
      "id": "Fz6FTwiSlgtB",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka2nZvdMmjzL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7afc201e-7b20-465a-c285-d082ef4e15c3"
      },
      "source": [
        "\"\"\"\n",
        "model = fpGrowth.fit(basket_data)\n",
        "\n",
        "# Display frequent itemsets.\n",
        "model.freqItemsets.show()\n",
        "items = model.freqItemsets\n",
        "\n",
        "# Display generated association rules.\n",
        "model.associationRules.show()\n",
        "rules = model.associationRules\n",
        "\n",
        "# transform examines the input items against all the association rules and summarize the consequents as prediction\n",
        "model.transform(basket_data).show()\n",
        "transformed = model.transform(basket_data)\n",
        "\"\"\""
      ],
      "id": "Ka2nZvdMmjzL",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nmodel = fpGrowth.fit(basket_data)\\n\\n# Display frequent itemsets.\\nmodel.freqItemsets.show()\\nitems = model.freqItemsets\\n\\n# Display generated association rules.\\nmodel.associationRules.show()\\nrules = model.associationRules\\n\\n# transform examines the input items against all the association rules and summarize the consequents as prediction\\nmodel.transform(basket_data).show()\\ntransformed = model.transform(basket_data)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y3eYwlUhklx"
      },
      "source": [
        "# Test of the algorithms"
      ],
      "id": "6Y3eYwlUhklx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAmmpjQxh37m"
      },
      "source": [
        "We extract a subset of 500 rows from the dataset to test out that our algorithms work as expected. We define min_support as 1% of the count of the rows."
      ],
      "id": "MAmmpjQxh37m"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFU3nax7hwzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0637d56-2632-4272-b656-5cd03145aa89"
      },
      "source": [
        "import pandas as pd\n",
        "minsup = 0.01\n",
        "num_rows = 500\n",
        "sup = minsup*num_rows\n",
        "\n",
        "minid = basket_data.take(num_rows)\n",
        "minid = spark.sparkContext.parallelize(minid)\n",
        "minid.take(5)"
      ],
      "id": "DFU3nax7hwzB",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(tconst='tt0000009', nconsts=['nm0063086', 'nm0183823', 'nm1309758']),\n",
              " Row(tconst='tt0000335', nconsts=['nm1010955', 'nm1012612', 'nm1011210', 'nm1012621', 'nm0675239', 'nm0675260']),\n",
              " Row(tconst='tt0000502', nconsts=['nm0215752', 'nm0252720']),\n",
              " Row(tconst='tt0000574', nconsts=['nm0846887', 'nm0846894', 'nm3002376', 'nm0170118']),\n",
              " Row(tconst='tt0000615', nconsts=['nm3071427', 'nm0581353', 'nm0888988', 'nm0240418', 'nm0346387', 'nm0218953'])]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeweibBnjlt-"
      },
      "source": [
        "We start by exectuing the classic implementation of apriori. Is compulsory to  collect the data from the RDD since this is a non distributed implementation."
      ],
      "id": "UeweibBnjlt-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvT1hHJejqx-"
      },
      "source": [
        "apriori1 = list(apriori_unlimited_k(minid.collect(), sup))"
      ],
      "id": "bvT1hHJejqx-",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJQ80_vgj8GV"
      },
      "source": [
        "The we have the Apriori implementation with map-reduce"
      ],
      "id": "uJQ80_vgj8GV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE7l29m1j7m9"
      },
      "source": [
        "apriori2 = apriorihmap_unlimited_k(minid, sup).collect()"
      ],
      "id": "TE7l29m1j7m9",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLsmu3F9k71N"
      },
      "source": [
        "Follow the implementation with SON. The data must be repartioned on the finded sweet-spot number of partitions"
      ],
      "id": "NLsmu3F9k71N"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6IRRQKJ2rF7"
      },
      "source": [
        "minid = minid.repartition(num_partitions)\n",
        "son = son_m_r(minid, sup).collect()"
      ],
      "id": "y6IRRQKJ2rF7",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "son"
      ],
      "metadata": {
        "id": "UyTfsJLEOPyL",
        "outputId": "ae336041-ee01-4e03-d1de-142b33c00428",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UyTfsJLEOPyL",
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('nm0539049', 5),\n",
              " ('nm0294276', 5),\n",
              " ('nm0526234', 5),\n",
              " ('nm0577476', 5),\n",
              " ('nm0505354', 7),\n",
              " ('nm0068213', 5),\n",
              " ('nm0165691', 6),\n",
              " ('nm0003425', 9),\n",
              " ('nm0252476', 7),\n",
              " ('nm0926280', 12),\n",
              " ('nm0691995', 8),\n",
              " ('nm0190516', 7),\n",
              " ('nm0243918', 5),\n",
              " ('nm0679170', 6),\n",
              " ('nm0746008', 6),\n",
              " ('nm0681933', 10),\n",
              " ('nm0768187', 5),\n",
              " ('nm0908390', 6),\n",
              " ('nm0392059', 5),\n",
              " ('nm0622772', 5),\n",
              " ('nm0292407', 10),\n",
              " ('nm0885818', 5),\n",
              " ('nm0516974', 9),\n",
              " ('nm0110838', 6),\n",
              " ('nm0074186', 6),\n",
              " ('nm0642190', 6),\n",
              " ('nm0140054', 10),\n",
              " ('nm0169878', 5),\n",
              " ('nm0016799', 8),\n",
              " ('nm0528022', 7),\n",
              " ('nm0330280', 5),\n",
              " ('nm0676473', 7),\n",
              " ('nm0163540', 8),\n",
              " ('nm0366008', 6)]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BAUF1yUIrL9"
      },
      "source": [
        "son_v2 = son_m_r_v2(minid, sup).collect()"
      ],
      "id": "5BAUF1yUIrL9",
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "son_v2"
      ],
      "metadata": {
        "id": "YH3UmVrqQ5aa",
        "outputId": "a24da173-db8f-4aff-e522-2465ccb7bce7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "YH3UmVrqQ5aa",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('nm0539049',), 5)]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Dl2cFhxoIp1"
      },
      "source": [
        "Then we also train the in-library implementation of FPGrowth to have a comparison with a correct algorithm"
      ],
      "id": "6Dl2cFhxoIp1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-JGaLC6oIL2"
      },
      "source": [
        "# initialize\n",
        "fpGrowth.setMinSupport(minsup)\n",
        "model = fpGrowth.fit(minid.toDF())\n",
        "\n",
        "# get itemsets\n",
        "fp_growth = model.freqItemsets.collect()"
      ],
      "id": "i-JGaLC6oIL2",
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdmS1h6zsGCd"
      },
      "source": [
        "# trasform the output of FPGrowth same as our implementations\n",
        "def trasform_format(data):\n",
        "  strings = []\n",
        "  tuples = []\n",
        "  for d in data:\n",
        "    if len(d[0]) == 1:\n",
        "      strings.append((d[0][0], d[1]))\n",
        "    else:\n",
        "      tuples.append((tuple(sorted(d[0])),d[1]))\n",
        "  return strings + tuples\n",
        "\n",
        "# keep only singleton and tuples in fpgrowth result and trasform the format of results\n",
        "fp_growth = trasform_format(fp_growth)"
      ],
      "id": "KdmS1h6zsGCd",
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP1FgwrOwz5F"
      },
      "source": [
        "Let's put the obtained result in a tabular way."
      ],
      "id": "aP1FgwrOwz5F"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOfyQmTHiyfM",
        "outputId": "8b979d40-40d6-4582-a80a-5279adf4bb79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df1 = pd.DataFrame([x[1] for x in apriori1], index=[x[0] for x in apriori1], columns =['Apriori'])\n",
        "df2 = pd.DataFrame([x[1] for x in apriori2], index=[x[0] for x in apriori2], columns =['Apriori MR'])\n",
        "df3 = pd.DataFrame([x[1] for x in son], index=[x[0] for x in son], columns =['SON'])\n",
        "df4 = pd.DataFrame([x[1] for x in fp_growth], index=[x[0] for x in fp_growth], columns =['FPGrowth'])\n",
        "\n",
        "df = pd.concat([df1, df2, df3, df4], axis=1)\n",
        "df[\"Equal\"] = df.nunique(axis = 1, dropna=False) == 1       \n",
        "df"
      ],
      "id": "lOfyQmTHiyfM",
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-56dc4831-9ca5-4dde-8113-7d1325e13d06\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Apriori</th>\n",
              "      <th>Apriori MR</th>\n",
              "      <th>SON</th>\n",
              "      <th>FPGrowth</th>\n",
              "      <th>Equal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>nm0140054</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0691995</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0243918</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0169878</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0539049</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0330280</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0768187</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0528022</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0681933</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0003425</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0016799</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0679170</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0294276</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0516974</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0252476</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0074186</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0110838</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0505354</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0292407</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0926280</th>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0642190</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0526234</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0746008</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0676473</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0392059</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0622772</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0577476</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0908390</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0163540</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0190516</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0068213</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0165691</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0366008</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nm0885818</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(nm0140054, nm0243918)</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(nm0003425, nm0016799)</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(nm0505354, nm0926280)</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(nm0292407, nm0505354)</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(nm0292407, nm0926280)</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(nm0292407, nm0642190)</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(nm0642190, nm0926280)</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(nm0577476, nm0622772)</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(nm0292407, nm0505354, nm0926280)</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(nm0292407, nm0642190, nm0926280)</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56dc4831-9ca5-4dde-8113-7d1325e13d06')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-56dc4831-9ca5-4dde-8113-7d1325e13d06 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-56dc4831-9ca5-4dde-8113-7d1325e13d06');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                   Apriori  Apriori MR   SON  FPGrowth  Equal\n",
              "nm0140054                               10          10  10.0        10   True\n",
              "nm0691995                                8           8   8.0         8   True\n",
              "nm0243918                                5           5   5.0         5   True\n",
              "nm0169878                                5           5   5.0         5   True\n",
              "nm0539049                                5           5   5.0         5   True\n",
              "nm0330280                                5           5   5.0         5   True\n",
              "nm0768187                                5           5   5.0         5   True\n",
              "nm0528022                                7           7   7.0         7   True\n",
              "nm0681933                               10          10  10.0        10   True\n",
              "nm0003425                                9           9   9.0         9   True\n",
              "nm0016799                                8           8   8.0         8   True\n",
              "nm0679170                                6           6   6.0         6   True\n",
              "nm0294276                                5           5   5.0         5   True\n",
              "nm0516974                                9           9   9.0         9   True\n",
              "nm0252476                                7           7   7.0         7   True\n",
              "nm0074186                                6           6   6.0         6   True\n",
              "nm0110838                                6           6   6.0         6   True\n",
              "nm0505354                                7           7   7.0         7   True\n",
              "nm0292407                               10          10  10.0        10   True\n",
              "nm0926280                               12          12  12.0        12   True\n",
              "nm0642190                                6           6   6.0         6   True\n",
              "nm0526234                                5           5   5.0         5   True\n",
              "nm0746008                                6           6   6.0         6   True\n",
              "nm0676473                                7           7   7.0         7   True\n",
              "nm0392059                                5           5   5.0         5   True\n",
              "nm0622772                                5           5   5.0         5   True\n",
              "nm0577476                                5           5   5.0         5   True\n",
              "nm0908390                                6           6   6.0         6   True\n",
              "nm0163540                                8           8   8.0         8   True\n",
              "nm0190516                                7           7   7.0         7   True\n",
              "nm0068213                                5           5   5.0         5   True\n",
              "nm0165691                                6           6   6.0         6   True\n",
              "nm0366008                                6           6   6.0         6   True\n",
              "nm0885818                                5           5   5.0         5   True\n",
              "(nm0140054, nm0243918)                   5           5   NaN         5  False\n",
              "(nm0003425, nm0016799)                   7           7   NaN         7  False\n",
              "(nm0505354, nm0926280)                   5           5   NaN         5  False\n",
              "(nm0292407, nm0505354)                   5           5   NaN         5  False\n",
              "(nm0292407, nm0926280)                   9           9   NaN         9  False\n",
              "(nm0292407, nm0642190)                   5           5   NaN         5  False\n",
              "(nm0642190, nm0926280)                   5           5   NaN         5  False\n",
              "(nm0577476, nm0622772)                   5           5   NaN         5  False\n",
              "(nm0292407, nm0505354, nm0926280)        5           5   NaN         5  False\n",
              "(nm0292407, nm0642190, nm0926280)        5           5   NaN         5  False"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perfomance comparison"
      ],
      "metadata": {
        "id": "-s6W5Y0DOKQ6"
      },
      "id": "-s6W5Y0DOKQ6"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "R_bZe7tm4SD-"
      },
      "id": "R_bZe7tm4SD-",
      "execution_count": null,
      "outputs": []
    }
  ]
}